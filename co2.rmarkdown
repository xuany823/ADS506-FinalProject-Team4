---
title: "CO2 Analysis"
format: pdf
Contributor: Michelle_Wang, Vinh_Dao, Duy_Dang
---

## **ADS506-FinalProject-Team4**

Overview: The analysis uses monthly CO2 measurements from Mauna Loa Observatory.

NOAA Global Monitoring Laboratory\
Atmospheric CO₂, Mauna Loa Observatory – Monthly Dataset\
<https://gml.noaa.gov/ccgg/trends/data.html>

# 1. Data Preparation:

```{r}
#| message: false
#| warning: false
library(tidyverse)
library(fpp3)
library(gt)
library(feasts)
library(dplyr)
library(fable)
library(fabletools)
#library(urca)
```

```{r}
co2_raw <- read_csv("data/co2.csv")
```

# 2. EDA

## 2.(1-4) **Basic Descriptive Statistics**

```{r}
# 1. Basic cleaning / handle missing values
sum(is.na(co2_raw))

# 2. Create a proper time index and tsibble
co2_ts <- co2_raw |>
  mutate(Month = yearmonth(paste(year, month, "01", sep = "-"))) |>
  as_tsibble(index = Month)

# 3. Confirm tsibble
co2_ts |>
  knitr::kable(digits = 1, caption = "Overall summary of CO2 average" )
  
#4. Summary of co2 data
co2_ts |>
  summarise(
    start_year   = min(year(Month)),
    end_year     = max(year(Month)),
    n_months     = n(),
    mean_co2     = mean(average, na.rm = TRUE),
    sd_co2       = sd(average, na.rm = TRUE),
    min_co2      = min(average, na.rm = TRUE),
    max_co2      = max(average, na.rm = TRUE),
    mean_deseas  = mean(deseasonalized, na.rm = TRUE))

co2_ts |>
  knitr::kable(digits = 1, caption = "Overall summary of CO2 average" )
```

## 2.5. Time Series **Visualization (**Plot)

```{r}
# 5. Time Seires Plot
# 5.1 all raw data time series plot
co2_ts |>
  autoplot(average) +
  labs(title = "Monthly Mauna Loa CO2 (ppm)",
       x = "Year",y = "CO2 (ppm)")

# 5.2. plot of latest 20 years 
latest_year <- max(year(co2_ts$Month), na.rm = TRUE)

co2_ts |>
  filter(year(Month) >= latest_year - 20) |>
  autoplot(average) +
  labs(title = "Monthly Mauna Loa CO2 (ppm), Last 20 Years", 
       x = "Year", y = "CO2 (ppm)")

# 5.3 Compare average and deseasonalized
co2_ts |>pivot_longer(
  cols = c(average, deseasonalized), names_to = "series", values_to = "value") |>
  autoplot(value) +
  labs(title = "Mauna Loa CO2: Raw vs. Deseasonalized",
    x = "Year",
    y = "CO2 (ppm)")

```

## 2.6. Seasonality exploration

```{r}
# 
# 6.1 Seasonal Plot
co2_ts |>
  gg_season(average) +
  labs(title = "Seasonal Plot of Monthly CO2", y = "CO2 (ppm)",x = "Month")

# 6.2 Subseries plot 
co2_ts |>
  gg_subseries(average) +
  labs(title = "Subseries Plot of Monthly CO2 by Month",
    y = "CO2 (ppm)", x = "Year")
```

## 2.7. Distribution & outliners

```{r}
# 7. Distribution & outliers
# 7.1 Histogram of CO2
co2_ts |>
  ggplot(aes(x = average)) +
  geom_histogram(bins = 30) +
  labs(
    title = "Distribution of Monthly CO2",
    x = "CO2 (ppm)",
    y = "Count"
  )

# 7.2 Boxplot by month
co2_ts |>
  mutate(Month_f = factor(month(Month, label = TRUE))) |>
  ggplot(aes(x = Month_f, y = average)) +
  geom_boxplot() +
  labs(
    title = "Monthly CO2 Distribution by Calendar Month",
    x = "Month",
    y = "CO2 (ppm)"
  )

# 7.3 Boxplot by decade
co2_ts |>
  mutate(decade = factor((year(Month) %/% 10) * 10)) |>
  ggplot(aes(x = decade, y = average)) +
  geom_boxplot() +
  labs(
    title = "CO2 Levels by Decade",
    x = "Decade",
    y = "CO2 (ppm)"
  )
```

## 2.8. Autocorrelation & decomposition

```{r}
# 8. Autocorrelation & decomposition
# 8.1 ACF of CO₂
co2_ts |>
  ACF(average) |>
  autoplot() +
  labs(title = "ACF of Monthly CO2", x = "Lag (months)", y = "ACF")

# 8.2 STL decomposition (trend + season + remainder)
co2_stl <- co2_ts |>
  model(stl = STL(average ~ season(window = "periodic"))) |>
  components()

autoplot(co2_stl) + labs(title = "STL Decomposition of Monthly CO2")

```

## 2.9. Simple check on ndays / data quality

```{r}
# 9. Simple check on ndays / data quality
# Relationship between ndays and average CO2
co2_ts |>
  ggplot(aes(x = ndays, y = average)) +
  geom_point(alpha = 0.6) +
  labs(title = "Relationship between Number of Days Sampled and Monthly CO2",
    x = "Number of Days (ndays)",
    y = "CO2 (ppm)"
  )

# Trend of measurement uncertainty over time
co2_ts |> autoplot(unc) + labs(
    title = "Measurement Uncertainty (unc) Over Time",
    x = "Year", y = "Uncertainty")
```

# 3. Preprocessing

Model Diagnostics

## 3.1 Evaluate if smoothing is needed

Residual Diagnostic Plots

```{r}
# KPSS test for stationarity
co2_ts |>
    features(average, c(unitroot_kpss, unitroot_ndiffs, unitroot_nsdiffs))

# Plot the ACF/PACF on the stationary time series
co2_ts |> gg_tsdisplay(average, plot_type = "partial")
```

We evaluated whether additional smoothing was necessary by examining the stability of the trend and seasonal patterns in the raw monthly CO2 series (Figure1). Figure 1 showed a very smooth long-term upward trajectory with minimal short-term noise, indicating that the underlying trend is already well-behaved and does not require moving averages or other smoothing techniques. Seasonal diagnostics (Figure 4 and Figure 5) showed a highly regular and stable annual cycle, further suggesting that no smoothing is needed to refine or enhance the seasonal pattern. The STL decomposition plot (Figure 10) reinforced these observations: the trend component was smooth and continuous, and the remainder showed no unusual fluctuations. Together, these results indicate that the CO2 series does not require additional smoothing prior to modeling, and the raw monthly values can be used directly in TSLM or ARIMA-based forecasts. However, further smoothing would be necessary if short-term volatility, irregular spikes, or noise were present that obscured the underlying structure, as smoothing would help isolate the signal and improve model interpretability prior to forecasting.

## 3.2 **Evaluate if differencing is needed**

To determine whether differencing was required, our process is using visual diagnostics, autocorrelation patterns, formal unit root testing, and ARIMA model behavior. The raw series exhibits a persistent upward trend, and its ACF shows a slow, gradual decay - both signs of non-stationarity.

The KPSS test returned a very small p-value (0.01), leading us to reject the null hypothesis of stationarity. This indicates that the raw CO2 series is non-stationary and therefore requires at least one regular difference (d = 1) to achieve stationarity prior to modeling.

```{r}
# ACF 
co2_ts |> 
  ACF(average) |> 
  autoplot()

# PACF
co2_ts |>
  PACF(average) |> 
  autoplot()
```

## 3.3 **Evaluate if transformation (e.g., Box–Cox) is needed**

Given the findings from previous EDA steps, we ran some preprocessing steps by fitting an automatic ARIMA model and examining its residual diagnostics to further assess whether a variance-stabilizing transformation such as Box–Cox was necessary. The residual plots (Figure 11)from gg_tsresiduals() showed no systematic structure, no increasing spread over time, and no evidence of non-constant variance, indicating that the model errors behave approximately like white noise. The ACF of the residuals also remained within sampling bounds, suggesting no remaining autocorrelation that would indicate a need for transformation. From the plot, these diagnostics indicate that a Box-Cox or log transformation is not required for this dataset.

Auto ARIMA for residual dignostics

```{r}
fit <- co2_ts |>
  model(
    arima = ARIMA(average))

fit |>
  select(arima) |>
  gg_tsresiduals()
```

If here we are diagnosing that a Box–Cox transformation was not required, I was referring specifically to the variance-stability diagnostic. The residual plots did not show increasing variance or multiplicative seasonal effects, so from a theoretical standpoint, a transformation isn’t needed to satisfy model assumptions. However, that does not mean a transformation could not improve the model. In practice, even with roughly stable variance, a Box–Cox scan can still be useful for detecting mild skewness or subtle amplitude shifts that only become visible after differencing. Sometimes a small λ adjustment can reduce low-lag autocorrelation and lead to more stable forecast errors across horizons. So again, similar to seasonal differencing: Theory: transformation is not necessary for variance stabilization.

Practice: testing a Box–Cox transformation may still enhance model flexibility and residual behavior. These two perspectives are complementary rather than contradictory.

## 3.4 Summary of EDA & Preprocessing Insights

A strong, nonlinear upward trend Highly stable annual seasonality No problematic outliers Minimal missing data and clean measurement structure Strong autocorrelation and non-stationarity( theoretically) No strong need for variance transformation (but may be explored for model refinement) ARIMA models will require differencing

## 3.5 Tsibble Formatting (Before modeling)

```{r}
co2 <- co2_ts |>
  mutate(Month = yearmonth(paste(year, month, sep = "-"))) |>
  as_tsibble(index = Month) |>
  select(Month, average) |>
  filter(!is.na(average), average > 0)
```

# 4. Model Building

Based on the earlier EDA and preprocessing steps, the Mauna Loa CO₂ series shows a strong nonlinear upward trend, highly regular annual seasonality, and approximately constant variance. Therefore, we proceed without any log or Box–Cox transformation and fit several automatic benchmark models to the untransformed monthly averages. To enable out-of-sample evaluation, we split the data into an 80/20 train–test partition and compare model performance across four classes: TSLM, ETS, ARIMA, and NNAR.

## 4.1 Train/Test Split (80/20)

```{r}

# co2: tsibble with index = Month (or yearmonth) and response = average
# Replace 'co2_ts' and 'average' with actual object/column names 

n_total  <- nrow(co2)
n_train  <- floor(0.8 * n_total)

co2_train <- co2 |> slice(1:n_train)

co2_test  <- co2 |> slice((n_train + 1):n_total)

co2_train
co2_test
```

## 4.2 Models

Build auto TSLM, ETS and ARIMA using the untransformed series. Build TSLM, ETS, and ARIMA using the log-transformed series. Include a seasonal naive model (on the untransformed data)

```{r}
# 5.2 Models to Fit (all automatic, and transformation)

co2_fit <- co2_train |>
  model(
    auto_tslm  = TSLM(average ~ trend() + season()),
    auto_ets   = ETS(average),
    auto_arima = ARIMA(average),
    log_tslm = TSLM(log(average) ~ trend() + season()),
    log_ets  = ETS(log(average)),
    log_arima = ARIMA(log(average)),
    snaive    = SNAIVE(average))
    #auto_nnar  = NNETAR(average, repeats = 5)

```

## 4.3 Training Accuracy Table

```{r}
# Training accuracy on the 80% training set
train_acc <- co2_fit |>
  accuracy() |>
  arrange(RMSE) |>
  select(.model, .type, RMSE, MAE, MAPE, MPE)

knitr::kable(train_acc,
  digits = 2,
  caption = "Training accuracy for automatic training models (80% training set)")
```

## 4.4 Forecasting and Forecast Accuracy on Test Set

```{r}
# Forecast horizon = length of test set
co2_fc <- co2_fit |>
  forecast(new_data = co2_test)

#co2_fc

# Plot forecasts against the full series
co2_fc |> autoplot(co2) +
  labs(title = "Forecasts from automatic TSLM, ETS, ARIMA, and NNAR models",
    x = "Month", y = "Mauna Loa CO₂ (ppm)"
  )

# Forecast (test) accuracy on the 20% hold-out period
test_acc <- co2_fc |>
  accuracy(co2_test) |>
  arrange(RMSE) |>
  select(.model, .type, RMSE, MAE, MAPE, MPE)

knitr::kable(test_acc, digits = 2,
             caption = "Forecast accuracy on the 20% hold-out period")

```

## 4.5 Forecasting CO2 series -  Accuracy Comparison with Cross-validation

### Compare models the first 10 years of the CO2 training data

-   Use only the first 10 years of the data
-   Create the 3 models above on the log transformed data
-   Include a seasonal naive model (on the untransformed data)
-   Create an ensemble model of the 3 regression models using a simple average
-   Forecast the next year (1968)
-   Report the model metrics sorted by RMSE

### Repeat the previous model with a rolling forecasting origin of 1 year increments

-   create a tsibble with cross-validation series that starts with 10 years of data and adds one year at time through Sep 2024. (Hint: use `stretch_tsibble`)
-   Fit the same 5 models from the previous step
-   Report the model metrics sorted by RMSE for each model across all validation intervals.

# 5. Model Comparison and Selection

As above training accuracy Table and Forecasting accuracy(test set) Table summarize the in-sample and out-of-sample performance for all candidate models.\
On the training set, the automatic ARIMA and ETS models (with and without log transformation) achieved very similar RMSE and MAE, while the TSLM variants and the seasonal naïve model performed noticeably worse. However, the forecast accuracy on the 20% hold-out period tells a clearer story: the log-transformed ARIMA model (`log_arima`) achieves the lowest RMSE and MAE, followed by the log-transformed ETS model (`log_ets`). Both transformed models substantially outperform their untransformed counterparts, the TSLM models, and the naïve benchmark.

These results suggest that even though our EDA did not indicate a strong theoretical need for a variance-stabilizing transformation, the log scale leads to better generalization for ARIMA and ETS. Given its best forecast accuracy and relatively simple structure, we select the **log ARIMA model** as the final model for reporting and interpretation in the remainder of the analysis.

# 6. Final Model Diagnostics

```{r}
# Extract the final model: log_arima
final_fit <- co2_fit |>
  select(log_arima)

report(final_fit)
```

Residual diagnostics for final log-ARIMA model

ljung-box test with sufficient lags

```{r}
# Residual diagnostics for final log-ARIMA model
final_fit |>
  gg_tsresiduals() +
  labs(title = "Residual diagnostics for final log-ARIMA model")

# perform a ljung-box test with sufficient lags
final_fit |>
  augment() |>
  features(.innov, ljung_box, lag=24)
```

The residual diagnostics indicate that the log-ARIMA model provides a well-specified fit.

The residuals show no remaining trend or seasonality, autocorrelation stays within sampling bounds, and the histogram is approximately symmetric. Overall, the model errors behave like white noise, suggesting that the model adequately captures the underlying structure of the CO₂ series.

```{r}
# Optional: produce back-transformed forecasts from the final model
final_fc <- final_fit |>
  forecast(new_data = co2_test) |>
  mutate(.mean = exp(.mean))

autoplot(final_fc, co2) +
  labs(
    title = "Final log-ARIMA forecasts back-transformed to CO2 (ppm)",
    x = "Month",
    y = "Mauna Loa CO₂ (ppm)"
  )
```

Finally, we generate forecasts from the log-ARIMA model and back-transform them to the original ppm scale for interpretation. The forecast path smoothly extends the historical Keeling Curve, and the prediction intervals widen gradually into the future, reflecting increasing uncertainty while remaining consistent with the long-term upward trend observed in the data.

We performed a Ljung–Box test at lag 24, following the common guideline of using roughly two seasonal cycles for monthly data. The resulting p-value (0.53) provides no evidence of remaining autocorrelation, indicating that the log-ARIMA model has adequately captured the trend and seasonality and that the residuals behave like white noise.

# 7. Final Model Forecasts Use the best performing model to create a forecast for each month in next 12 month (2025 Sep to 2026 Aug). 

